import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from scipy.stats import skew, kurtosis, shapiro
from sklearn.cluster import KMeans
import warnings

warnings.filterwarnings("ignore")

# PARAMETERS
SYMBOL = 'BTCUSDT'
INTERVAL = '15m'
DAYS = 365

def get_binance_data(symbol=SYMBOL, interval=INTERVAL, days=DAYS):
    limit = 1000  # Max per request
    end_time = datetime.now()
    start_time = end_time - timedelta(days=days)
    all_data = []

    while start_time < end_time:
        url = f"https://api.binance.com/api/v3/klines"
        params = {
            'symbol': symbol,
            'interval': interval,
            'limit': limit,
            'endTime': int(end_time.timestamp() * 1000)
        }
        response = requests.get(url, params=params)
        data = response.json()
        if not data:
            break
        all_data = data + all_data
        end_time = datetime.fromtimestamp(data[0][0] / 1000.0 - 60)

    columns = ['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume', '_1', '_2', '_3', '_4', '_5', '_6']
    df = pd.DataFrame(all_data, columns=columns)
    df = df[['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']]
    df[['Open', 'High', 'Low', 'Close', 'Volume']] = df[['Open', 'High', 'Low', 'Close', 'Volume']].astype(float)
    df['DateTime'] = pd.to_datetime(df['timestamp'], unit='ms')
    df['Hour'] = df['DateTime'].dt.hour
    df['Day'] = df['DateTime'].dt.date
    df.sort_values('DateTime', inplace=True)
    return df.reset_index(drop=True)

def analyze_oscillations(df):
    df['Delta'] = df['Close'].diff()
    df['Volatility'] = (df['High'] - df['Low']) / df['Open'] * 100
    df['abs_delta'] = df['Delta'].abs()

    # Sort columns for better readability
    df = df[['DateTime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Hour', 'Day', 'Delta', 'Volatility', 'abs_delta']]

    # Global statistics
    global_stats = pd.DataFrame({
        'Mean': [df['Delta'].mean()],
        'StdDev': [df['Delta'].std()],
        'Skewness': [skew(df['Delta'].dropna())],
        'Kurtosis': [kurtosis(df['Delta'].dropna())],
        'Shapiro_W': [shapiro(df['Delta'].dropna().sample(min(5000, len(df))))[0]],
        'Autocorr_1': [df['Delta'].autocorr(lag=1)],
        'SharpeRatio': [df['Delta'].mean() / df['Delta'].std()],
        'CoeffVariation': [df['Delta'].std() / abs(df['Delta'].mean())],
    })

    # Hourly statistics
    hourly_stats = df.groupby('Hour').agg({
        'Delta': ['mean', 'std', 'max', 'min'],
        'Volatility': ['mean', 'max']
    })
    hourly_stats[('RiskScore', 'mean')] = hourly_stats[('Delta', 'mean')].abs() * hourly_stats[('Volatility', 'mean')]

    # Conditional statistics
    delta_thresh = df['abs_delta'].quantile(0.9)
    volatility_thresh = df['Volatility'].quantile(0.9)
    conditional_stats = pd.DataFrame({
        'HighDeltaMoves': [(df['abs_delta'] > delta_thresh).sum()],
        'HighVolMoves': [(df['Volatility'] > volatility_thresh).sum()],
        'HighDeltaAndVol': [((df['abs_delta'] > delta_thresh) & (df['Volatility'] > volatility_thresh)).sum()]
    })

    # Clustering
    clustering_df = df[['Delta', 'Volatility', 'Volume']].dropna().copy()
    kmeans = KMeans(n_clusters=4, random_state=0).fit(clustering_df)
    clustering_df['Cluster'] = kmeans.labels_
    df = df.iloc[clustering_df.index]  # align with clustering_df
    df['Cluster'] = clustering_df['Cluster'].values
    cluster_summary = clustering_df.groupby('Cluster').agg(['mean', 'std'])

    # Top oscillations
    top_oscillations = df.copy()
    top_oscillations = top_oscillations.sort_values(by='abs_delta', ascending=False).head(100)
    top_oscillations['RiskScore'] = top_oscillations['abs_delta'] * top_oscillations['Volatility']
    top_oscillations = top_oscillations[['DateTime', 'Open', 'Close', 'Delta', 'Volatility', 'Hour', 'Day', 'Cluster', 'RiskScore']]

    top_osc_summary = top_oscillations.groupby('Cluster').agg({
        'Delta': ['mean', 'std', 'count'],
        'Volatility': ['mean', 'std'],
        'RiskScore': ['mean', 'max']
    })
    top_osc_summary.columns = ['_'.join(col) for col in top_osc_summary.columns]
    top_osc_summary.reset_index(inplace=True)

    # Deep analyses

    # Cluster Timeline
    cluster_timeline = df.groupby(['Day', 'Cluster']).size().unstack(fill_value=0)
    cluster_timeline = cluster_timeline.rolling(window=3).mean()

    # Cluster Hourly Distribution
    cluster_hourly = df.groupby(['Hour', 'Cluster']).size().unstack(fill_value=0)
    cluster_hourly_pct = cluster_hourly.div(cluster_hourly.sum(axis=1), axis=0)

    # Cluster Transitions
    df['Cluster_next'] = df['Cluster'].shift(-1)
    transition_matrix = pd.crosstab(df['Cluster'], df['Cluster_next'], normalize='index')

    # Cluster Day Summary
    dominant_cluster_by_day = df.groupby('Day')['Cluster'].agg(lambda x: x.value_counts().idxmax())
    day_cluster_summary = df.groupby('Day').agg({
        'Delta': ['mean', 'std'],
        'Volatility': ['mean', 'max'],
        'Volume': 'sum'
    })
    day_cluster_summary['DominantCluster'] = dominant_cluster_by_day

    # Export Excel 
    now = datetime.now()
    filename = f'full_results_V6_{now.strftime("%Y%m%d_%H%M")}.xlsx'
    with pd.ExcelWriter(filename) as writer:
        df.to_excel(writer, sheet_name='RawData', index=False)
        global_stats.to_excel(writer, sheet_name='GlobalStats', index=False)
        hourly_stats.to_excel(writer, sheet_name='HourlyStats')
        conditional_stats.to_excel(writer, sheet_name='ConditionalStats', index=False)
        cluster_summary.to_excel(writer, sheet_name='Clustering')
        top_oscillations.to_excel(writer, sheet_name='TopOscillations', index=False)
        top_osc_summary.to_excel(writer, sheet_name='TopOscByCluster', index=False)
        cluster_hourly_pct.to_excel(writer, sheet_name='ClusterHourlyPct')
        transition_matrix.to_excel(writer, sheet_name='TransitionMatrix')
        cluster_timeline.to_excel(writer, sheet_name='ClusterTimeline')
        day_cluster_summary.to_excel(writer, sheet_name='DayClusterSummary')

    print(f"Analysis V6 completed. Results exported to {filename}")

# EXECUTION 
df = get_binance_data()
analyze_oscillations(df)
